{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f50315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba28c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_csv(\"cleaned_books.csv\")\n",
    "df_ratings = pd.read_csv(\"cleaned_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90176f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the ratings per book to max 1000\n",
    "df_ratings = df_ratings[df_ratings[\"book_id\"].isin(df_books.index)]\n",
    "df_ratings = (\n",
    "    df_ratings.groupby(\"book_id\")\n",
    "    .apply(lambda x: x.sample(min(1000, len(x))))\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a03878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457285"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ratings)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab4437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map IDs to indices\n",
    "user_map = {u: i for i, u in enumerate(df_ratings['user_id'].unique())}\n",
    "item_map = {b: i for i, b in enumerate(df_ratings['book_id'].unique())}\n",
    "df_ratings['user_idx'] = df_ratings['user_id'].map(user_map)\n",
    "df_ratings['item_idx'] = df_ratings['book_id'].map(item_map)\n",
    "\n",
    "n_users = len(user_map)\n",
    "n_items = len(item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81afc57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8c69fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train = np.zeros((n_users, n_items))\n",
    "\n",
    "for row in train_df.itertuples():\n",
    "    R_train[row.user_idx, row.item_idx] = row.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfd1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # Number of latent factors\n",
    "U, sigma, Vt = svds(R_train, k=k)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "predicted_ratings_matrix = np.dot(np.dot(U, sigma), Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9105f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(pred_matrix, test_df):\n",
    "    preds = []\n",
    "    truths = []\n",
    "\n",
    "    for row in test_df.itertuples():\n",
    "        user_idx = row.user_idx\n",
    "        item_idx = row.item_idx\n",
    "        pred_rating = pred_matrix[user_idx, item_idx]\n",
    "        preds.append(pred_rating)\n",
    "        truths.append(row.rating)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(truths, preds))\n",
    "    return round(rmse, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df5ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(pred_matrix, test_df):\n",
    "    preds = []\n",
    "    truths = []\n",
    "\n",
    "    for row in test_df.itertuples():\n",
    "        user_idx = row.user_idx\n",
    "        item_idx = row.item_idx\n",
    "        pred_rating = pred_matrix[user_idx, item_idx]\n",
    "        preds.append(pred_rating)\n",
    "        truths.append(row.rating)\n",
    "\n",
    "    mae = mean_absolute_error(truths, preds)\n",
    "    return round(mae, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7963458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=5):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            hits += 1\n",
    "            score += hits / (i + 1)\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def reciprocal_rank(actual, predicted):\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff8f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_map_mrr(pred_matrix, train_df, test_df, k=10, threshold=4.0):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_score = 0\n",
    "    total_rr = 0\n",
    "    user_count = 0\n",
    "    train_user_items = train_df.groupby(\"user_idx\")[\"item_idx\"].apply(set)\n",
    "\n",
    "    for user in tqdm(test_df['user_idx'].unique(), desc=\"Processing evaluation (MRR, MAP, Precision)\", unit=\"user\"):\n",
    "        rated_items = train_user_items.get(user, set())\n",
    "        user_pred = pred_matrix[user]\n",
    "        \n",
    "        # Exclude items seen in training\n",
    "        unseen_items = np.setdiff1d(np.arange(pred_matrix.shape[1]), list(rated_items))\n",
    "        top_k_items = unseen_items[np.argsort(user_pred[unseen_items])[::-1][:k]]\n",
    "\n",
    "        # True relevant items in test set for this user\n",
    "        user_test = test_df[test_df['user_idx'] == user]\n",
    "        relevant_items = user_test[user_test['rating'] >= threshold]['item_idx'].values\n",
    "        \n",
    "        # Calculate precision\n",
    "        correct += len(set(top_k_items) & set(relevant_items))\n",
    "        total += k\n",
    "        \n",
    "        actual_items = test_df[(test_df['user_idx'] == user) & (test_df['rating'] >= threshold)]['item_idx'].tolist()\n",
    "        #Calculate MAP and MRR\n",
    "        if actual_items:\n",
    "            total_score += apk(actual_items, list(top_k_items), k)\n",
    "            total_rr += reciprocal_rank(actual_items, list(top_k_items))\n",
    "            user_count += 1      \n",
    "\n",
    "    precision = round(correct / total, 4)\n",
    "    map = round(total_score / user_count, 4) if user_count else 0\n",
    "    mrr = round(total_rr / user_count, 4) if user_count else 0\n",
    "    return precision, map, mrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79e7dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.9095\n",
      "MAE: 3.7877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing evaluation (MRR, MAP, Precision): 100%|██████████| 53408/53408 [16:37<00:00, 53.53user/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5: 0.0185\n",
      "MRR@5: 0.0574\n",
      "Precision@5: 0.0284\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", compute_rmse(predicted_ratings_matrix, test_df))\n",
    "print(\"MAE:\", compute_mae(predicted_ratings_matrix, test_df))\n",
    "\n",
    "precision, map, mrr = pre_map_mrr(predicted_ratings_matrix, train_df, test_df, k=5, threshold=4.0)\n",
    "print(\"MAP@5:\", map)\n",
    "print(\"MRR@5:\", mrr)\n",
    "print(\"Precision@5:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2d49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_id, R_train, predicted_ratings, n=5):\n",
    "    user_idx = user_map[user_id]\n",
    "    user_ratings = R_train[user_idx]\n",
    "    preds = predicted_ratings[user_idx]\n",
    "    \n",
    "    # Books not rated by user\n",
    "    unrated_indices = np.where(user_ratings == 0)[0]\n",
    "    recommended_indices = unrated_indices[np.argsort(preds[unrated_indices])[::-1][:n]]\n",
    "\n",
    "    # Map back to book IDs\n",
    "    item_map_rev = {i: b for b, i in item_map.items()}\n",
    "    recommended_books = [(item_map_rev[i], preds[i]) for i in recommended_indices]\n",
    "    return recommended_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6207564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images in a DataFrame\n",
    "def display_images(df, image_column):\n",
    "    # Create an HTML representation of the DataFrame with images\n",
    "    html = df.to_html(escape=False, formatters={\n",
    "        image_column: lambda url: f'<img src=\"{url}\" width=\"100\">'\n",
    "    })\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db24bfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>title</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1159</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>Stones from the River</td>\n",
       "      <td><img src=\"https://images.gr-assets.com/books/1366513909m/77163.jpg\" width=\"100\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>The Invention of Wings</td>\n",
       "      <td><img src=\"https://images.gr-assets.com/books/1386699861m/18079776.jpg\" width=\"100\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>291</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>Cutting for Stone</td>\n",
       "      <td><img src=\"https://images.gr-assets.com/books/1327931601m/3591262.jpg\" width=\"100\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1198</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>A Little Life</td>\n",
       "      <td><img src=\"https://images.gr-assets.com/books/1446469353m/22822858.jpg\" width=\"100\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>The Nightingale</td>\n",
       "      <td><img src=\"https://images.gr-assets.com/books/1451446316m/21853621.jpg\" width=\"100\"></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rcmd = recommend_books(123, R_train, predicted_ratings_matrix)\n",
    "rcmd_df = pd.DataFrame(rcmd, columns=[\"book_id\", \"predicted_rating\"])\n",
    "rcmd_df = rcmd_df.merge(df_books[['book_id', 'title', 'image_url']], on='book_id', how='left')\n",
    "rcmd_df['predicted_rating'] = rcmd_df['predicted_rating'].round(4)\n",
    "display_images(rcmd_df, 'image_url')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
